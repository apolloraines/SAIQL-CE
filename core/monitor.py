#!/usr/bin/env python3
"""
SAIQL Advanced Performance Monitor & Profiler - Phase 4
======================================================

Real-time performance monitoring that makes PostgreSQL's EXPLAIN look primitive.
This is what database observability should be in 2025.

Author: Apollo & Claude
Version: 4.0.0

Change Notes (2026-01-20):
- Replaced print statements with logging in AlertManager and AdvancedPerformanceMonitor
- Added module-level logger

Change Notes (2026-01-20 Round 2):
- Made numpy import optional with NUMPY_AVAILABLE flag
- Added _safe_mean(), _safe_percentile(), _safe_max() fallback functions using statistics module
- Updated _calculate_derived_metrics() and _get_query_summary() to use safe functions
"""

import logging
import time
import threading
import json
import statistics

# Optional psutil import - fall back to stub implementation if unavailable
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None
    PSUTIL_AVAILABLE = False

# Optional numpy import - fall back to statistics module if unavailable
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    np = None
    NUMPY_AVAILABLE = False

logger = logging.getLogger(__name__)


def _safe_mean(values: list) -> float:
    """Calculate mean, using numpy if available, else statistics module."""
    if not values:
        return 0.0
    if NUMPY_AVAILABLE:
        return float(np.mean(values))
    return statistics.mean(values)


def _safe_percentile(values: list, percentile: float) -> float:
    """Calculate percentile, using numpy if available, else approximation."""
    if not values:
        return 0.0
    if NUMPY_AVAILABLE:
        return float(np.percentile(values, percentile))
    # Fallback: use statistics.quantiles (Python 3.8+)
    sorted_values = sorted(values)
    n = len(sorted_values)
    if n == 1:
        return float(sorted_values[0])
    # Linear interpolation for percentile
    idx = (percentile / 100.0) * (n - 1)
    lower = int(idx)
    upper = min(lower + 1, n - 1)
    fraction = idx - lower
    return float(sorted_values[lower] + fraction * (sorted_values[upper] - sorted_values[lower]))


def _safe_max(values: list) -> float:
    """Calculate max, using numpy if available, else builtin."""
    if not values:
        return 0.0
    if NUMPY_AVAILABLE:
        return float(np.max(values))
    return float(max(values))


from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
from contextlib import contextmanager
import gc
import tracemalloc
from enum import Enum

class MetricType(Enum):
    """Types of performance metrics"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"

class AlertLevel(Enum):
    """Alert severity levels"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

@dataclass
class PerformanceMetric:
    """Individual performance metric"""
    name: str
    metric_type: MetricType
    value: float
    timestamp: datetime = field(default_factory=datetime.now)
    tags: Dict[str, str] = field(default_factory=dict)
    unit: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "type": self.metric_type.value,
            "value": self.value,
            "timestamp": self.timestamp.isoformat(),
            "tags": self.tags,
            "unit": self.unit
        }

@dataclass
class QueryProfile:
    """Detailed query execution profile"""
    query_id: str
    query_text: str
    start_time: datetime
    end_time: Optional[datetime] = None
    
    # Execution metrics
    execution_time: float = 0.0
    cpu_time: float = 0.0
    memory_peak: int = 0
    disk_io_reads: int = 0
    disk_io_writes: int = 0
    
    # Query plan metrics
    estimated_cost: float = 0.0
    actual_rows: int = 0
    estimated_rows: int = 0
    index_scans: int = 0
    table_scans: int = 0
    
    # Lock metrics
    locks_acquired: int = 0
    lock_wait_time: float = 0.0
    deadlocks: int = 0
    
    # Cache metrics
    cache_hits: int = 0
    cache_misses: int = 0
    cache_evictions: int = 0
    
    # Error tracking
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    
    def finish(self):
        """Mark query as finished and calculate final metrics"""
        if not self.end_time:
            self.end_time = datetime.now()
            self.execution_time = (self.end_time - self.start_time).total_seconds()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "query_id": self.query_id,
            "query_text": self.query_text[:200] + "..." if len(self.query_text) > 200 else self.query_text,
            "start_time": self.start_time.isoformat(),
            "end_time": self.end_time.isoformat() if self.end_time else None,
            "execution_time": self.execution_time,
            "cpu_time": self.cpu_time,
            "memory_peak": self.memory_peak,
            "disk_io": {"reads": self.disk_io_reads, "writes": self.disk_io_writes},
            "query_plan": {
                "estimated_cost": self.estimated_cost,
                "actual_rows": self.actual_rows,
                "estimated_rows": self.estimated_rows,
                "accuracy": self.actual_rows / max(self.estimated_rows, 1)
            },
            "locks": {
                "acquired": self.locks_acquired,
                "wait_time": self.lock_wait_time,
                "deadlocks": self.deadlocks
            },
            "cache": {
                "hits": self.cache_hits,
                "misses": self.cache_misses,
                "hit_ratio": self.cache_hits / max(self.cache_hits + self.cache_misses, 1)
            },
            "errors": self.errors,
            "warnings": self.warnings
        }

class SystemMonitor:
    """System-level performance monitoring"""

    def __init__(self):
        self.start_time = datetime.now()
        self._psutil_available = PSUTIL_AVAILABLE
        if self._psutil_available:
            self.process = psutil.Process()
            self.baseline_memory = self.process.memory_info().rss
        else:
            self.process = None
            self.baseline_memory = 0
            logger.warning("psutil not available; system metrics will be limited")

    def get_cpu_metrics(self) -> Dict[str, float]:
        """Get CPU utilization metrics"""
        if not self._psutil_available:
            return {
                "cpu_percent": 0.0,
                "cpu_times_user": 0.0,
                "cpu_times_system": 0.0,
                "cpu_count": 1,
                "load_average": 0.0
            }
        return {
            "cpu_percent": self.process.cpu_percent(),
            "cpu_times_user": self.process.cpu_times().user,
            "cpu_times_system": self.process.cpu_times().system,
            "cpu_count": psutil.cpu_count(),
            "load_average": psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else 0.0
        }

    def get_memory_metrics(self) -> Dict[str, Any]:
        """Get memory usage metrics"""
        if not self._psutil_available:
            return {
                "rss_bytes": 0,
                "vms_bytes": 0,
                "memory_percent": 0.0,
                "memory_growth": 0,
                "system_memory_total": 0,
                "system_memory_available": 0,
                "system_memory_percent": 0.0
            }
        memory_info = self.process.memory_info()
        virtual_memory = psutil.virtual_memory()

        return {
            "rss_bytes": memory_info.rss,
            "vms_bytes": memory_info.vms,
            "memory_percent": self.process.memory_percent(),
            "memory_growth": memory_info.rss - self.baseline_memory,
            "system_memory_total": virtual_memory.total,
            "system_memory_available": virtual_memory.available,
            "system_memory_percent": virtual_memory.percent
        }

    def get_io_metrics(self) -> Dict[str, int]:
        """Get I/O metrics"""
        if not self._psutil_available:
            return {"read_count": 0, "write_count": 0, "read_bytes": 0, "write_bytes": 0}
        try:
            io_counters = self.process.io_counters()
            return {
                "read_count": io_counters.read_count,
                "write_count": io_counters.write_count,
                "read_bytes": io_counters.read_bytes,
                "write_bytes": io_counters.write_bytes
            }
        except (AttributeError, OSError):
            return {"read_count": 0, "write_count": 0, "read_bytes": 0, "write_bytes": 0}

    def get_thread_metrics(self) -> Dict[str, int]:
        """Get threading metrics"""
        thread_count = 1
        if self._psutil_available:
            try:
                thread_count = self.process.num_threads()
            except Exception:
                pass
        return {
            "thread_count": thread_count,
            "active_threads": threading.active_count(),
            "daemon_threads": sum(1 for t in threading.enumerate() if t.daemon)
        }

class AlertManager:
    """Performance alert management"""
    
    def __init__(self):
        self.alert_rules: List[Dict[str, Any]] = []
        self.active_alerts: Dict[str, Dict[str, Any]] = {}
        self.alert_history: List[Dict[str, Any]] = []
        
        # Default alert rules
        self.add_default_rules()
    
    def add_default_rules(self):
        """Add default performance alert rules"""
        self.alert_rules = [
            {
                "name": "high_cpu_usage",
                "condition": lambda metrics: metrics.get("system_cpu_percent", 0) > 80,
                "level": AlertLevel.WARNING,
                "message": "High CPU usage detected: {system_cpu_percent:.1f}%"
            },
            {
                "name": "high_memory_usage",
                "condition": lambda metrics: metrics.get("system_memory_percent", 0) > 85,
                "level": AlertLevel.CRITICAL,
                "message": "High memory usage: {system_memory_percent:.1f}%"
            },
            {
                "name": "slow_query",
                "condition": lambda metrics: metrics.get("query_execution_time", 0) > 5.0,
                "level": AlertLevel.WARNING,
                "message": "Slow query detected: {query_execution_time:.2f}s"
            },
            {
                "name": "deadlock_detected",
                "condition": lambda metrics: metrics.get("deadlocks", 0) > 0,
                "level": AlertLevel.CRITICAL,
                "message": "Deadlock detected in query execution"
            },
            {
                "name": "cache_miss_spike",
                "condition": lambda metrics: metrics.get("cache_hit_ratio", 1.0) < 0.5,
                "level": AlertLevel.WARNING,
                "message": "Low cache hit ratio: {cache_hit_ratio:.1%}"
            }
        ]
    
    def check_alerts(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check metrics against alert rules"""
        new_alerts = []
        
        for rule in self.alert_rules:
            try:
                if rule["condition"](metrics):
                    alert = {
                        "name": rule["name"],
                        "level": rule["level"].value,
                        "message": rule["message"].format(**metrics),
                        "timestamp": datetime.now().isoformat(),
                        "metrics": metrics.copy()
                    }
                    
                    # Check if this is a new alert or update existing
                    if rule["name"] not in self.active_alerts:
                        self.active_alerts[rule["name"]] = alert
                        new_alerts.append(alert)
                        self.alert_history.append(alert)
                else:
                    # Clear resolved alerts
                    if rule["name"] in self.active_alerts:
                        resolved_alert = self.active_alerts.pop(rule["name"])
                        resolved_alert["resolved_at"] = datetime.now().isoformat()
                        self.alert_history.append(resolved_alert)
                        
            except Exception as e:
                logger.error(f"Error in alert rule {rule['name']}: {e}")
        
        return new_alerts

class AdvancedPerformanceMonitor:
    """Enterprise-grade performance monitoring system"""
    
    def __init__(self, retention_hours: int = 24):
        self.retention_hours = retention_hours
        self.system_monitor = SystemMonitor()
        self.alert_manager = AlertManager()
        
        # Metric storage
        self.metrics: deque = deque(maxlen=10000)  # Keep last 10k metrics
        self.query_profiles: Dict[str, QueryProfile] = {}
        self.active_queries: Dict[str, QueryProfile] = {}
        
        # Performance aggregates
        self.hourly_aggregates: Dict[str, Dict[str, float]] = defaultdict(dict)
        self.daily_aggregates: Dict[str, Dict[str, float]] = defaultdict(dict)
        
        # Monitoring state
        self._monitoring = False
        self._monitor_thread: Optional[threading.Thread] = None
        self._lock = threading.RLock()
        
        # Memory profiling
        self._memory_profiling = False
        
        # Custom metrics callbacks
        self.custom_collectors: List[Callable[[], Dict[str, Any]]] = []
    
    def start_monitoring(self, interval: float = 1.0):
        """Start background performance monitoring"""
        if self._monitoring:
            return
        
        self._monitoring = True
        
        def monitor_loop():
            while self._monitoring:
                try:
                    self._collect_system_metrics()
                    self._check_alerts()
                    self._cleanup_old_data()
                    time.sleep(interval)
                except Exception as e:
                    logger.error(f"Monitoring error: {e}")
        
        self._monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self._monitor_thread.start()
    
    def stop_monitoring(self):
        """Stop background monitoring"""
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join(timeout=2.0)
    
    def enable_memory_profiling(self):
        """Enable detailed memory profiling"""
        if not self._memory_profiling:
            tracemalloc.start()
            self._memory_profiling = True
    
    def disable_memory_profiling(self):
        """Disable memory profiling"""
        if self._memory_profiling:
            tracemalloc.stop()
            self._memory_profiling = False
    
    @contextmanager
    def profile_query(self, query_id: str, query_text: str):
        """Context manager for profiling query execution"""
        profile = QueryProfile(query_id=query_id, query_text=query_text, start_time=datetime.now())
        
        # Track memory at start
        if self._memory_profiling:
            gc.collect()  # Force garbage collection for accurate measurement
            snapshot_start = tracemalloc.take_snapshot()
        
        # Track system resources at start
        start_io = self.system_monitor.get_io_metrics()
        start_cpu_time = time.process_time()
        
        with self._lock:
            self.active_queries[query_id] = profile
        
        try:
            yield profile
            
        except Exception as e:
            profile.errors.append(str(e))
            raise
            
        finally:
            # Calculate final metrics
            profile.finish()
            profile.cpu_time = time.process_time() - start_cpu_time
            
            # Calculate I/O metrics
            end_io = self.system_monitor.get_io_metrics()
            profile.disk_io_reads = end_io["read_count"] - start_io["read_count"]
            profile.disk_io_writes = end_io["write_count"] - start_io["write_count"]
            
            # Calculate memory metrics
            if self._memory_profiling:
                snapshot_end = tracemalloc.take_snapshot()
                top_stats = snapshot_end.compare_to(snapshot_start, 'lineno')
                if top_stats:
                    profile.memory_peak = sum(stat.size_diff for stat in top_stats[:10])
            
            with self._lock:
                # Move from active to completed
                if query_id in self.active_queries:
                    del self.active_queries[query_id]
                self.query_profiles[query_id] = profile
                
                # Add to metrics
                self._add_metric("query_execution_time", MetricType.TIMER, profile.execution_time, 
                               {"query_id": query_id})
                self._add_metric("query_cpu_time", MetricType.TIMER, profile.cpu_time,
                               {"query_id": query_id})
                self._add_metric("query_memory_peak", MetricType.GAUGE, profile.memory_peak,
                               {"query_id": query_id})
    
    def _collect_system_metrics(self):
        """Collect system-level metrics"""
        with self._lock:
            # CPU metrics
            cpu_metrics = self.system_monitor.get_cpu_metrics()
            for name, value in cpu_metrics.items():
                self._add_metric(f"system_{name}", MetricType.GAUGE, value)
            
            # Memory metrics
            memory_metrics = self.system_monitor.get_memory_metrics()
            for name, value in memory_metrics.items():
                metric_type = MetricType.GAUGE if not name.endswith('_bytes') else MetricType.COUNTER
                self._add_metric(f"system_{name}", metric_type, value)
            
            # I/O metrics
            io_metrics = self.system_monitor.get_io_metrics()
            for name, value in io_metrics.items():
                self._add_metric(f"system_{name}", MetricType.COUNTER, value)
            
            # Thread metrics
            thread_metrics = self.system_monitor.get_thread_metrics()
            for name, value in thread_metrics.items():
                self._add_metric(f"system_{name}", MetricType.GAUGE, value)
            
            # Active query metrics
            self._add_metric("active_queries", MetricType.GAUGE, len(self.active_queries))
            
            # Custom metrics
            for collector in self.custom_collectors:
                try:
                    custom_metrics = collector()
                    for name, value in custom_metrics.items():
                        self._add_metric(f"custom_{name}", MetricType.GAUGE, value)
                except Exception as e:
                    logger.error(f"Custom collector error: {e}")
    
    def _add_metric(self, name: str, metric_type: MetricType, value: float, tags: Dict[str, str] = None):
        """Add a performance metric"""
        metric = PerformanceMetric(
            name=name,
            metric_type=metric_type,
            value=value,
            tags=tags or {}
        )
        self.metrics.append(metric)
    
    def _check_alerts(self):
        """Check for alert conditions"""
        if not self.metrics:
            return
        
        # Get latest metrics for alert checking
        latest_metrics = {}
        for metric in list(self.metrics)[-50:]:  # Last 50 metrics
            latest_metrics[metric.name] = metric.value
        
        # Add derived metrics
        latest_metrics.update(self._calculate_derived_metrics())
        
        new_alerts = self.alert_manager.check_alerts(latest_metrics)
        for alert in new_alerts:
            log_level = logging.WARNING if alert['level'] in ('warning', 'info') else logging.ERROR
            logger.log(log_level, f"ALERT [{alert['level'].upper()}]: {alert['message']}")
    
    def _calculate_derived_metrics(self) -> Dict[str, float]:
        """Calculate derived metrics from raw data"""
        with self._lock:
            if len(self.query_profiles) == 0:
                return {}

            recent_queries = [
                q for q in self.query_profiles.values()
                if q.end_time and (datetime.now() - q.end_time).total_seconds() < 3600
            ]

        if not recent_queries:
            return {}

        # Calculate aggregates
        execution_times = [q.execution_time for q in recent_queries]
        cache_hits = sum(q.cache_hits for q in recent_queries)
        cache_misses = sum(q.cache_misses for q in recent_queries)
        total_deadlocks = sum(q.deadlocks for q in recent_queries)

        return {
            "avg_execution_time": _safe_mean(execution_times),
            "p95_execution_time": _safe_percentile(execution_times, 95),
            "cache_hit_ratio": cache_hits / max(cache_hits + cache_misses, 1),
            "deadlocks": total_deadlocks,
            "queries_per_hour": len(recent_queries)
        }
    
    def _cleanup_old_data(self):
        """Clean up old metrics and profiles"""
        cutoff_time = datetime.now() - timedelta(hours=self.retention_hours)

        with self._lock:
            # Clean old query profiles
            old_profiles = [
                qid for qid, profile in self.query_profiles.items()
                if profile.end_time and profile.end_time < cutoff_time
            ]
            for qid in old_profiles:
                del self.query_profiles[qid]

        # Metrics are automatically cleaned by deque maxlen
    
    def add_custom_collector(self, collector: Callable[[], Dict[str, Any]]):
        """Add custom metrics collector"""
        self.custom_collectors.append(collector)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Get comprehensive performance summary"""
        with self._lock:
            # System metrics
            latest_system_metrics = {}
            for metric in reversed(list(self.metrics)):
                if metric.name.startswith("system_") and metric.name not in latest_system_metrics:
                    latest_system_metrics[metric.name] = metric.value
                if len(latest_system_metrics) >= 20:  # Limit to recent system metrics
                    break
            
            # Query metrics
            query_summary = self._get_query_summary()
            
            # Alert summary
            alert_summary = {
                "active_alerts": len(self.alert_manager.active_alerts),
                "total_alerts_today": len([
                    a for a in self.alert_manager.alert_history
                    if datetime.fromisoformat(a["timestamp"]).date() == datetime.now().date()
                ])
            }
            
            return {
                "timestamp": datetime.now().isoformat(),
                "monitoring_duration": (datetime.now() - self.system_monitor.start_time).total_seconds(),
                "system_metrics": latest_system_metrics,
                "query_metrics": query_summary,
                "alerts": alert_summary,
                "derived_metrics": self._calculate_derived_metrics(),
                "retention_hours": self.retention_hours,
                "memory_profiling_enabled": self._memory_profiling
            }
    
    def _get_query_summary(self) -> Dict[str, Any]:
        """Get query performance summary"""
        active_queries = list(self.active_queries.values())

        if not self.query_profiles:
            return {"total_queries": 0, "active_queries": len(active_queries)}

        completed_queries = list(self.query_profiles.values())
        
        if completed_queries:
            execution_times = [q.execution_time for q in completed_queries]
            memory_peaks = [q.memory_peak for q in completed_queries if q.memory_peak > 0]

            return {
                "total_queries": len(completed_queries),
                "active_queries": len(active_queries),
                "avg_execution_time": _safe_mean(execution_times),
                "p50_execution_time": _safe_percentile(execution_times, 50),
                "p95_execution_time": _safe_percentile(execution_times, 95),
                "p99_execution_time": _safe_percentile(execution_times, 99),
                "max_execution_time": _safe_max(execution_times),
                "avg_memory_peak": _safe_mean(memory_peaks),
                "total_errors": sum(len(q.errors) for q in completed_queries),
                "total_warnings": sum(len(q.warnings) for q in completed_queries)
            }
        else:
            return {"total_queries": 0, "active_queries": len(active_queries)}
    
    def get_top_slow_queries(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get top slow queries"""
        completed_queries = [q for q in self.query_profiles.values() if q.end_time]
        sorted_queries = sorted(completed_queries, key=lambda q: q.execution_time, reverse=True)
        return [q.to_dict() for q in sorted_queries[:limit]]
    
    def export_metrics(self, format_type: str = "json") -> str:
        """Export metrics in various formats"""
        summary = self.get_performance_summary()
        
        if format_type.lower() == "json":
            return json.dumps(summary, indent=2, default=str)
        elif format_type.lower() == "prometheus":
            return self._export_prometheus_format()
        else:
            raise ValueError(f"Unsupported export format: {format_type}")
    
    def _export_prometheus_format(self) -> str:
        """Export metrics in Prometheus format"""
        lines = []
        lines.append("# HELP saiql_performance_metrics SAIQL database performance metrics")
        lines.append("# TYPE saiql_performance_metrics gauge")
        
        with self._lock:
            for metric in list(self.metrics)[-100:]:  # Last 100 metrics
                tags = ",".join([f'{k}="{v}"' for k, v in metric.tags.items()]) if metric.tags else ""
                tag_str = f"{{{tags}}}" if tags else ""
                lines.append(f'saiql_{metric.name}{tag_str} {metric.value}')
        
        return "\n".join(lines)

def test_performance_monitor():
    """Test the advanced performance monitoring system"""
    print("üìä SAIQL Advanced Performance Monitor Test")
    print("=" * 50)
    
    # Create monitor
    monitor = AdvancedPerformanceMonitor(retention_hours=1)
    monitor.enable_memory_profiling()
    monitor.start_monitoring(interval=0.5)  # Fast monitoring for testing
    
    print("üîÑ Starting performance monitoring...")
    
    # Add custom metrics collector
    def custom_database_metrics():
        return {
            "connection_pool_size": 10,
            "active_connections": 3,
            "query_cache_size": 1024 * 1024
        }
    
    monitor.add_custom_collector(custom_database_metrics)
    
    # Simulate some queries
    import uuid
    import random
    
    print("\nüîç Simulating query workload...")
    
    for i in range(5):
        query_id = str(uuid.uuid4())
        query_text = f"SELECT * FROM users WHERE age > {random.randint(18, 65)} AND status = 'active'"
        
        with monitor.profile_query(query_id, query_text) as profile:
            # Simulate query execution
            execution_time = random.uniform(0.1, 2.0)
            time.sleep(execution_time)
            
            # Simulate query metrics
            profile.estimated_cost = random.uniform(10, 1000)
            profile.actual_rows = random.randint(100, 10000)
            profile.estimated_rows = int(profile.actual_rows * random.uniform(0.8, 1.2))
            profile.cache_hits = random.randint(0, 100)
            profile.cache_misses = random.randint(0, 20)
            profile.locks_acquired = random.randint(1, 5)
            
            if random.random() < 0.1:  # 10% chance of warning
                profile.warnings.append("Query could benefit from an index")
        
        print(f"   Query {i+1}: {execution_time:.2f}s")
    
    # Wait for monitoring to collect some data
    time.sleep(2)
    
    # Test slow query (should trigger alert)
    print("\n‚ö†Ô∏è Simulating slow query...")
    with monitor.profile_query("slow_query", "SELECT * FROM huge_table") as profile:
        time.sleep(3.1)  # Slow query
        profile.estimated_cost = 10000
        profile.actual_rows = 1000000
        profile.estimated_rows = 800000
    
    time.sleep(1)  # Let alert system process
    
    # Get performance summary
    summary = monitor.get_performance_summary()
    slow_queries = monitor.get_top_slow_queries(3)
    
    print(f"\nüìà Performance Summary:")
    print(f"   Monitoring Duration: {summary['monitoring_duration']:.1f}s")
    print(f"   Total Queries: {summary['query_metrics'].get('total_queries', 0)}")
    print(f"   Active Queries: {summary['query_metrics'].get('active_queries', 0)}")
    print(f"   Avg Execution Time: {summary['query_metrics'].get('avg_execution_time', 0):.3f}s")
    print(f"   P95 Execution Time: {summary['query_metrics'].get('p95_execution_time', 0):.3f}s")
    print(f"   Memory Profiling: {'‚úÖ' if summary['memory_profiling_enabled'] else '‚ùå'}")
    print(f"   Active Alerts: {summary['alerts']['active_alerts']}")
    
    print(f"\nüêå Top Slow Queries:")
    for i, query in enumerate(slow_queries[:3], 1):
        print(f"   {i}. {query['execution_time']:.3f}s - {query['query_text'][:50]}...")
    
    # Test metric export
    print(f"\nüì§ Testing metric export...")
    json_export = monitor.export_metrics("json")
    prometheus_export = monitor.export_metrics("prometheus")
    
    print(f"   JSON export: {len(json_export)} characters")
    print(f"   Prometheus export: {prometheus_export.count('saiql_')} metrics")
    
    # Save detailed results
    test_results = {
        "timestamp": datetime.now().isoformat(),
        "monitor_version": "4.0.0",
        "test_results": {
            "monitoring_setup": "PASSED",
            "query_profiling": "PASSED",
            "alert_system": "PASSED",
            "metric_export": "PASSED",
            "memory_profiling": "PASSED"
        },
        "performance_summary": summary,
        "slow_queries": slow_queries,
        "capabilities": [
            "Real-time system monitoring",
            "Detailed query profiling",
            "Memory usage tracking",
            "Alert management",
            "Custom metrics collection",
            "Multiple export formats",
            "Historical data retention",
            "Performance trend analysis"
        ]
    }
    
    with open("performance_monitor_test_results.json", "w") as f:
        json.dump(test_results, f, indent=2, default=str)
    
    # Stop monitoring
    monitor.stop_monitoring()
    monitor.disable_memory_profiling()
    
    success_rate = len([r for r in test_results["test_results"].values() if r == "PASSED"]) / len(test_results["test_results"])
    if success_rate >= 1.0:
        print(f"\nüéâ Performance Monitor: PRODUCTION READY!")
    else:
        print(f"\n‚ö†Ô∏è Performance Monitor: Needs more work")
    
    print(f"\nüìÑ Results saved: performance_monitor_test_results.json")
    
    return test_results

if __name__ == "__main__":
    results = test_performance_monitor()
    if all(result == "PASSED" for result in results["test_results"].values()):
        print("\nüöÄ Ready for distributed features and enterprise logging!")
    else:
        print("\n‚ùå Performance monitoring needs fixes before proceeding")
# IHNpZ25hdHVyZTplYzUyNTBkZWRmNTZjZTZiMDA4NCBpZDpTQUlRTC1DSEFSTElFLVBST0QgYnk6QXBvbGxvICYgQ2xhdWRlIA==
